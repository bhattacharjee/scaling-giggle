{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled6.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP+MZNW6g+sgtk0U5Zw3u6N",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bhattacharjee/scaling-giggle/blob/main/parse_electoral_roll.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Installing the dependencies first\n",
        "\n",
        "We rely on two packages mainly, pdf2image and pytesseract"
      ],
      "metadata": {
        "id": "4lDfdI34O-j6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6s6GED3bOyAO"
      },
      "outputs": [],
      "source": [
        "# Install the dependencies\n",
        "!pip install -q pdf2image\n",
        "!pip install -q pytesseract\n",
        "!pip install -q wget\n",
        "!pip install -q \"tqdm>=4.36.1\"\n",
        "\n",
        "!apt-get install poppler-utils                      > /dev/null 2>&1\n",
        "!apt-get install libleptonica-dev                   > /dev/null 2>&1\n",
        "!apt-get install tesseract-ocr tesseract-ocr-dev    > /dev/null 2>&1\n",
        "!apt-get install libtesseract-dev                   > /dev/null 2>&1\n",
        "!apt-get install tesseract-ocr                      > /dev/null 2>&1\n",
        "!apt-get install tesseract-ocr-eng                  > /dev/null 2>&1\n",
        "!apt-get install tesseract-ocr-eng                  > /dev/null 2>&1\n",
        "\n",
        "import os\n",
        "import re\n",
        "import wget\n",
        "import json\n",
        "import tqdm\n",
        "import shutil\n",
        "import tempfile\n",
        "import logging\n",
        "import pdf2image\n",
        "import pytesseract\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from functools import lru_cache\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " class Roll:\n",
        "    def __init__(self, url:str, save_directory:str=None)->list:\n",
        "        \"\"\"Construct the object which will be used for further\n",
        "        processing\n",
        "\n",
        "        Parameters:\n",
        "        url (str): The URL to the PDF (should not be a redirect)\n",
        "        \"\"\"\n",
        "\n",
        "        self.temp_file_name = None\n",
        "        self.pdf_url = url\n",
        "        self.pages = None\n",
        "        self.pages_text = list()\n",
        "        self.voters = list()\n",
        "\n",
        "        self.town = \"UNKNOWN\"\n",
        "        self.block = \"UNKNOWN\"\n",
        "        self.post_office = \"UNKNOWN\"\n",
        "        self.police_station = \"UNKNOWN\"\n",
        "        self.pin_code = \"000000\"\n",
        "        self.save_filename = None\n",
        "        self.savedir = save_directory\n",
        "        self.processed_df = None\n",
        "\n",
        "        self.errors = \"\"\n",
        "\n",
        "        self.save_filename = f\"{url.split('/')[-1]}.csv\"\n",
        "\n",
        "        self.re_other_name = re.compile(\\\n",
        "            \"((other.?s|father.?s|mother.?s|husband.?s)\\s?name\\s*[=:>-])\",\\\n",
        "            re.IGNORECASE)\n",
        "        self.re_other_name_for_match = re.compile(\\\n",
        "            \"((other.?s|father.?s|mother.?s|husband.?s)\\s?name\\s*[=:>-])\",\\\n",
        "            re.IGNORECASE)\n",
        "\n",
        "        self.re_name = re.compile(\"(name\\s*[=:>-])\", re.IGNORECASE)\n",
        "        self.re_name_for_match = re.compile(\".*(name\\s*[=:>-])\", re.IGNORECASE)\n",
        "\n",
        "        self.re_house_num = re.compile(\n",
        "            \"(House\\s*number\\s*[:=>-]\\s*)\", re.IGNORECASE)\n",
        "        self.re_house_num_for_match = re.compile(\n",
        "            \".*(House\\s*number\\s*[:=>-]\\s*)\", re.IGNORECASE)\n",
        "\n",
        "        self.re_age_gender = re.compile(\n",
        "            \"(age\\s*[:=>-]\\s*(\\d+)\\s*gender\\s*[:=>-]\\s*(male|female))\",\n",
        "            re.IGNORECASE\n",
        "        )\n",
        "        self.re_age_gender_for_match = re.compile(\n",
        "            \".*(age\\s*[:=>-]\\s*(\\d+)\\s*gender\\s*[:=>-]\\s*(male|female))\",\n",
        "            re.IGNORECASE\n",
        "        )\n",
        "\n",
        "        self.re_age = re.compile(\"(age\\s*[:=>-]\\s*(\\d*))\", re.IGNORECASE)\n",
        "        self.re_age_for_match = re.compile(\\\n",
        "                \".*(age\\s*[:=>-]\\s*(\\d*))\", re.IGNORECASE\n",
        "        )\n",
        "\n",
        "\n",
        "        self.page_details = {}\n",
        "\n",
        "        temp_file = tempfile.NamedTemporaryFile(delete=False)\n",
        "        self.temp_file_name = f\"{temp_file.name}.pdf\"\n",
        "        temp_file.close()\n",
        "    \n",
        "\n",
        "    @lru_cache(maxsize=256)\n",
        "    def get_text_as_list(self, text):\n",
        "        text = [s.strip() for s in text.split('\\n')]\n",
        "        text = [s for s in text if len(s) > 0]\n",
        "        names = list()\n",
        "        gender = list()\n",
        "        other = list()\n",
        "        return text\n",
        "\n",
        "    def download(self)->None:\n",
        "        \"\"\"Download the PDF file for this object\n",
        "\n",
        "        Returns:\n",
        "        None\n",
        "        \"\"\"\n",
        "        wget.download(self.pdf_url, self.temp_file_name)\n",
        "        if not os.path.isfile(self.temp_file_name) or \\\n",
        "            0 == os.stat(self.temp_file_name).st_size:\n",
        "            raise Exception(\"Failed to download file\")\n",
        "\n",
        "    def parse_first_page(self)->None:\n",
        "        \"\"\"\n",
        "        First page contains a lot of details, parse them\n",
        "        to fill the details of the geolocation of electoral roll\n",
        "        \"\"\"\n",
        "        re_town_village = re.compile(\".*town.*village\\s*[=:]\\s*(.*)\", \\\n",
        "                                    re.IGNORECASE)\n",
        "        re_post_office = re.compile(\".*Post.*Office\\s*[=:]\\s*(.*)\", \\\n",
        "                                    re.IGNORECASE)\n",
        "        re_pin_code = re.compile(\".*pin.*code.*\\s*([0-9]{6})\\s*\",\n",
        "                                    re.IGNORECASE)\n",
        "        re_block = re.compile(\".*block\\s[=:]\\s*(.*)\", re.IGNORECASE)\n",
        "        re_district = re.compile(\".*district\\s:\\s*(.*)\", re.IGNORECASE)\n",
        "        re_police_st = re.compile(\".*police.*station\\s*[=:]\\s*(.*)\",\\\n",
        "                                    re.IGNORECASE)\n",
        "        text = self.get_text_as_list(self.pages_text[0])\n",
        "        for s in text:\n",
        "            m = re_town_village.match(s)\n",
        "            if m:\n",
        "                self.town = m.group(1).strip()\n",
        "                continue\n",
        "            m = re_post_office.match(s)\n",
        "            if m:\n",
        "                self.post_office = m.group(1).strip()\n",
        "                continue\n",
        "            m = re_pin_code.match(s)\n",
        "            if m:\n",
        "                self.pin_code = m.group(1).strip()\n",
        "                continue\n",
        "            m = re_block.match(s)\n",
        "            if m:\n",
        "                self.block = m.group(1).strip()\n",
        "                continue\n",
        "            m = re_district.match(s)\n",
        "            if m:\n",
        "                self.district = m.group(1).strip()\n",
        "                continue\n",
        "            m = re_police_st.match(s)\n",
        "            if m:\n",
        "                self.police_station = m.group(1).strip()\n",
        "                continue\n",
        "        #print(f\"{self.town}, {self.post_office}, {self.block}, {self.police_station}, {self.district}, {self.pin_code}\")\n",
        "    \n",
        "    def convert_to_text(self, i:int)->None:\n",
        "        \"\"\"\n",
        "        Convert an image to text using pytesseract.\n",
        "        Pages from the PDF have already been converted to images\n",
        "        and stored in a dictionary indexed by page number\n",
        "        \"\"\"\n",
        "        s = pytesseract.image_to_string(self.pages[i])\n",
        "        s = s.replace(\"Age:\", \"\\r\\nAge:\")\n",
        "        s = s.replace(\"Photo is\", \"\\r\\nPhoto is\")\n",
        "        #s = s.replace(\"|\" , \"\\r\\n\")\n",
        "        #s = s.replace(\"[\", \"\\r\\n\")\n",
        "        #s = s.replace(\"]\", \"\\r\\n\")\n",
        "        return s\n",
        "\n",
        "    def get_other_name(self, s:str)->list:\n",
        "        \"\"\"\n",
        "        There can be several names in a single line as follows:\n",
        "        Fathers's Name: LAMJINGKMEN KHONGBUH Fathers' Name = LEM! CHALLAM Father's Name = PRECIOUSLY RYNGKHLEM\n",
        "        These need to be split and returned as a list\n",
        "        \"\"\"\n",
        "        matches = self.re_other_name.findall(s)\n",
        "        for a, b in matches:\n",
        "            s = s.replace(a, \"|\")\n",
        "        names = [x.strip() for x in s.split(\"|\")]\n",
        "        names = [x for x in names if len(x) > 0]\n",
        "        return names\n",
        "    \n",
        "    def get_name(self, s:str)->list:\n",
        "        \"\"\"\n",
        "        Do the same things for namess other's names\n",
        "        \"\"\"\n",
        "        matches = self.re_name.findall(s)\n",
        "        for a in matches:\n",
        "            s = s.replace(a, \"|\")\n",
        "        names = [x.strip() for x in s.split(\"|\")]\n",
        "        names = [x for x in names if len(x) > 0]\n",
        "        return names\n",
        "\n",
        "    def get_house_num(self, s:str)->list:\n",
        "        \"\"\"\n",
        "        Do the same thing for house number\n",
        "        \"\"\"\n",
        "        matches = self.re_house_num.findall(s)\n",
        "        for a in matches:\n",
        "            s = s.replace(a, \"|\")\n",
        "        names = [x.strip() for x in s.split(\"|\")]\n",
        "        names = [x for x in names if len(x) > 0]\n",
        "        return names\n",
        "\n",
        "    def get_age_gender(self, s:str)->tuple:\n",
        "        \"\"\"\n",
        "        Do the same thing for age and gender.\n",
        "        Age and gender appear in the same line.\n",
        "\n",
        "        This funciton matches lines that contain both age and gender\n",
        "        \n",
        "        There may be cases where lines contain only\n",
        "        age or only gender\n",
        "\n",
        "        Those are handled by get_age_only, and get_gender_only\n",
        "        \"\"\"\n",
        "        matches = self.re_age_gender.findall(s)\n",
        "        ages = list()\n",
        "        genders = list()\n",
        "        for _, age, gender in matches:\n",
        "            ages.append(age)\n",
        "            genders.append(gender)\n",
        "        return ages, genders\n",
        "\n",
        "    def get_age_only(self, s:str)->list:\n",
        "        \"\"\"\n",
        "        Do the same for age. Match lines that contain only age but not gender\n",
        "        \"\"\"\n",
        "        matches = self.re_age.findall(s)\n",
        "        ages = list()\n",
        "        assert(False)\n",
        "        return []\n",
        "\n",
        "    def get_temp_file_name(self)->str:\n",
        "        temp_file = tempfile.NamedTemporaryFile()\n",
        "        temp_file_name = f\"{temp_file.name}.json\"\n",
        "        temp_file.close()\n",
        "        return temp_file_name\n",
        "\n",
        "\n",
        "    def parse_roll_page(self, pagenum:int)->dict:\n",
        "        page_other_names = []\n",
        "        page_names = []\n",
        "        page_house_numbers = []\n",
        "        page_genders = []\n",
        "        page_ages = []\n",
        "\n",
        "        if not pagenum in self.pages_text:\n",
        "            raise Exception(\"page not found\")\n",
        "        text = self.get_text_as_list(self.pages_text[pagenum])\n",
        "        for s in text:\n",
        "            # Must match other name first, becuase\n",
        "            # the elif condition will also match\n",
        "            # and we should avoid that\n",
        "            if self.re_other_name_for_match.match(s):\n",
        "                page_other_names += self.get_other_name(s)\n",
        "            elif self.re_name.match(s):\n",
        "                page_names += self.get_name(s)\n",
        "            elif self.re_house_num_for_match.match(s):\n",
        "                page_house_numbers += self.get_house_num(s)\n",
        "            elif self.re_age_gender_for_match.match(s):\n",
        "                ages, genders = self.get_age_gender(s)\n",
        "                page_ages += ages\n",
        "                page_genders += genders\n",
        "            elif self.re_age_for_match.match(s):\n",
        "                page_ages += self.get_age_only()\n",
        "            else:\n",
        "                # print(f\"DIDN not match: |{s}|\")\n",
        "                pass\n",
        "\n",
        "\n",
        "        # Ensure that we have the same number of rows in each column\n",
        "        check_array = [len(page_other_names), len(page_names)]\n",
        "        check_array += [len(page_house_numbers), len(page_genders)]\n",
        "        check_array += [len(page_ages)]\n",
        "        # print(check_array)\n",
        "        for i in range(len(check_array) - 1):\n",
        "            x = check_array[i]\n",
        "            for y in check_array[i:]:\n",
        "                assert(min(x, 30) == min(y, 30))\n",
        "\n",
        "        ret_array = []\n",
        "        for name, o_name, housenum, gender, age in \\\n",
        "            zip(\\\n",
        "                page_names,\\\n",
        "                page_other_names,\\\n",
        "                page_house_numbers,\\\n",
        "                page_genders,\\\n",
        "                page_ages):\n",
        "            val = { \\\n",
        "                \"name\": name,\\\n",
        "                \"other_name\": o_name,\\\n",
        "                \"house_num\": housenum,\\\n",
        "                \"gender\": gender,\\\n",
        "                \"age\": age,\\\n",
        "                \"town\": self.town,\\\n",
        "                \"block\": self.block,\\\n",
        "                \"post_office\": self.post_office,\\\n",
        "                \"police_station\": self.police_station,\\\n",
        "                \"pin_code\": self.pin_code, \\\n",
        "            }\n",
        "            ret_array.append(val)\n",
        "\n",
        "        return ret_array\n",
        "            \n",
        "        \n",
        "\n",
        "    def process(self)->pd.DataFrame:\n",
        "        if not os.path.isfile(self.temp_file_name) or \\\n",
        "            0 == os.stat(self.temp_file_name).st_size:\n",
        "            raise Exception(\"Failed to download file\")\n",
        "        self.pages = pdf2image.convert_from_path(self.temp_file_name)\n",
        "        #self.pages = self.pages[:10] + [self.pages[-1]]\n",
        "        description = f\"Converting pages for {self.pdf_url}\"\n",
        "        self.pages_text = \\\n",
        "            {i: self.convert_to_text(i) for i in \\\n",
        "                tqdm.tqdm(range(len(self.pages)), desc=description) if i <= 4}\n",
        "        self.parse_first_page()\n",
        "        print(f\"Parsing {len(self.pages)} pages\")\n",
        "\n",
        "        count = 4\n",
        "        for i in tqdm.tqdm(range(3, len(self.pages) - 1)):\n",
        "            #print(f\"Parsing page: {i}\")\n",
        "\n",
        "            count -= 1\n",
        "            if 0 == count:\n",
        "                break\n",
        "\n",
        "            try:\n",
        "                self.voters += self.parse_roll_page(i)\n",
        "            except Exception as e:\n",
        "                print()\n",
        "                print(f\"Error in processing page: {i + 1}\")\n",
        "                print(f\"of {self.pdf_url}\")\n",
        "                print(f\"Skipped the page, please verify manually\")\n",
        "                self.errors += f\"Error in processing url: {self.pdf_url}\"\n",
        "                self.errors += f\"of {self.pdf_url}. \"\n",
        "                self.errors += f\"Skipped the page, please verify manually.\\n\"\n",
        "\n",
        "        temp_filename = self.get_temp_file_name() \n",
        "        with open(temp_filename, \"w\") as f:\n",
        "            json.dump(self.voters, f)\n",
        "        df = pd.read_json(temp_filename, orient=\"records\")\n",
        "        self.processed_df = df\n",
        "        return df\n",
        "        \n",
        "    def save(self)->None:\n",
        "        if self.savedir and \"\" != self.savedir and self.processed_df is not None:\n",
        "            save_filename = f\"/content/gdrive/MyDrive/{self.savedir}/{self.save_filename}\"\n",
        "            save_filename_err = f\"{save_filename}.err\"\n",
        "            save_dir = f\"/content/gdrive/MyDrive/{self.savedir}\"\n",
        "            try:\n",
        "                if os.path.exists(save_dir) and not os.path.isdir(save_dir):\n",
        "                    os.unlink(save_dir)\n",
        "                if not os.path.exists(save_dir):\n",
        "                    os.makedirs(\\\n",
        "                                f\"/content/gdrive/MyDrive/{self.savedir}\",\\\n",
        "                                exist_ok=True)\n",
        "                if self.errors != \"\":\n",
        "                    with open(save_filename_err, \"w\") as ferr:\n",
        "                        ferr.write(self.errors)\n",
        "                self.processed_df.to_csv(save_filename)\n",
        "            except Exception as e:\n",
        "                print(\"Failed to save the spreadsheet\")\n",
        "                print(e)\n",
        "                \n",
        "\n",
        "    def __del__(self):\n",
        "        if os.path.exists(self.temp_file_name):\n",
        "            os.unlink(self.temp_file_name)\n"
      ],
      "metadata": {
        "id": "REL4OKurSkC9"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Start here"
      ],
      "metadata": {
        "id": "_LlE-UIXcTOb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_url(roll_url:str, save_google_drive_directory:str)->tuple:\n",
        "    try:\n",
        "        drive.mount(\"/content/gdrive\")\n",
        "        roll = Roll(url=roll_url, save_directory=save_google_drive_directory)\n",
        "        roll.download()\n",
        "        df = roll.process()\n",
        "        roll.save()\n",
        "        return df.describe().T, df\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {roll_url} or in saving to {save_google_drive_directory}\")\n",
        "        print(e)\n",
        "        return None, None"
      ],
      "metadata": {
        "id": "9PEJbSjHLqTM"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add the links to the PDFs here:\n",
        "\n",
        "ONLINE_PDF_FILES_LIST = [\n",
        "    \"http://ceomeghalaya.nic.in/erolls/pdf/english/A001/A0010001.pdf\",\n",
        "    \"http://ceomeghalaya.nic.in/erolls/pdf/english/A001/A0010002.pdf\"\n",
        "]"
      ],
      "metadata": {
        "id": "0ux_Ro0tPBkC"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for url in tqdm.tqdm(ONLINE_PDF_FILES_LIST, desc=\"Processing URLs from ONLINE_PDF_FILES_LIST\"):\n",
        "    process_url(roll_url=url, save_google_drive_directory=\"DELETEME__Destination_directory\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aqjXKW5_MqHP",
        "outputId": "3ddcfc5e-ac60-4f24-fe7b-95e147134c28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing URLs from ONLINE_PDF_FILES_LIST:   0%|          | 0/2 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/gdrive\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Snr8O1YLOCAp",
        "outputId": "70dd528d-1d44-4840-9725-0e7aac448a4e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MyDrive  Othercomputers\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "M-2lep7uScdd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}