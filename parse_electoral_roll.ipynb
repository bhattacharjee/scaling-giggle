{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled6.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPLJsH8wYmFZbCoj9L34yTt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bhattacharjee/scaling-giggle/blob/main/parse_electoral_roll.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Installing the dependencies first\n",
        "\n",
        "We rely on two packages mainly, pdf2image and pytesseract"
      ],
      "metadata": {
        "id": "4lDfdI34O-j6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6s6GED3bOyAO"
      },
      "outputs": [],
      "source": [
        "# Install the dependencies\n",
        "!pip install pdf2image\n",
        "!pip install pytesseract\n",
        "!pip install wget\n",
        "!pip install -q \"tqdm>=4.36.1\"\n",
        "\n",
        "!apt-get install poppler-utils                      > /dev/null 2>&1\n",
        "!apt-get install libleptonica-dev                   > /dev/null 2>&1\n",
        "!apt-get install tesseract-ocr tesseract-ocr-dev    > /dev/null 2>&1\n",
        "!apt-get install libtesseract-dev                   > /dev/null 2>&1\n",
        "!apt-get install tesseract-ocr                      > /dev/null 2>&1\n",
        "!apt-get install tesseract-ocr-eng                  > /dev/null 2>&1\n",
        "!apt-get install tesseract-ocr-eng                  > /dev/null 2>&1\n",
        "\n",
        "import os\n",
        "import re\n",
        "import wget\n",
        "import json\n",
        "import tqdm\n",
        "import shutil\n",
        "import tempfile\n",
        "import logging\n",
        "import pdf2image\n",
        "import pytesseract\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from functools import lru_cache\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " STATE_ZERO = 0\n",
        " STATE_READING_NAMES = 1\n",
        " STATE_READING_OTHERS_NAME = 2\n",
        " STATE_READING_AGE_GENDER = 3\n",
        "\n",
        " class Roll:\n",
        "    def __init__(self, url:str, save_directory:str=None)->list:\n",
        "        \"\"\"Construct the object which will be used for further\n",
        "        processing\n",
        "\n",
        "        Parameters:\n",
        "        url (str): The URL to the PDF (should not be a redirect)\n",
        "        \"\"\"\n",
        "\n",
        "        self.temp_file_name = None\n",
        "        self.pdf_url = url\n",
        "        self.state = STATE_ZERO\n",
        "        self.pages = None\n",
        "        self.pages_text = list()\n",
        "        self.voters = list()\n",
        "\n",
        "        self.town = \"UNKNOWN\"\n",
        "        self.block = \"UNKNOWN\"\n",
        "        self.post_office = \"UNKNOWN\"\n",
        "        self.police_station = \"UNKNOWN\"\n",
        "        self.pin_code = \"000000\"\n",
        "        self.save_filename = None\n",
        "        self.savedir = save_directory\n",
        "        self.processed_df = None\n",
        "\n",
        "        self.errors = \"\"\n",
        "\n",
        "        self.save_filename = f\"{url.split('/')[-1]}.csv\"\n",
        "\n",
        "        self.re_other_name = re.compile(\\\n",
        "            \"((other.?s|father.?s|mother.?s|husband.?s)\\s?name\\s*[=:>-])\",\\\n",
        "            re.IGNORECASE)\n",
        "        self.re_other_name_for_match = re.compile(\\\n",
        "            \"((other.?s|father.?s|mother.?s|husband.?s)\\s?name\\s*[=:>-])\",\\\n",
        "            re.IGNORECASE)\n",
        "\n",
        "        self.re_name = re.compile(\"(name\\s*[=:>-])\", re.IGNORECASE)\n",
        "        self.re_name_for_match = re.compile(\".*(name\\s*[=:>-])\", re.IGNORECASE)\n",
        "\n",
        "        self.re_house_num = re.compile(\n",
        "            \"(House\\s*number\\s*[:=>-]\\s*)\", re.IGNORECASE)\n",
        "        self.re_house_num_for_match = re.compile(\n",
        "            \".*(House\\s*number\\s*[:=>-]\\s*)\", re.IGNORECASE)\n",
        "\n",
        "        self.re_age_gender = re.compile(\n",
        "            \"(age\\s*[:=>-]\\s*(\\d+)\\s*gender\\s*[:=>-]\\s*(male|female))\",\n",
        "            re.IGNORECASE\n",
        "        )\n",
        "        self.re_age_gender_for_match = re.compile(\n",
        "            \".*(age\\s*[:=>-]\\s*(\\d+)\\s*gender\\s*[:=>-]\\s*(male|female))\",\n",
        "            re.IGNORECASE\n",
        "        )\n",
        "\n",
        "        self.re_age = re.compile(\"(age\\s*[:=>-]\\s*(\\d*))\", re.IGNORECASE)\n",
        "        self.re_age_for_match = re.compile(\\\n",
        "                \".*(age\\s*[:=>-]\\s*(\\d*))\", re.IGNORECASE\n",
        "        )\n",
        "\n",
        "\n",
        "        self.page_details = {}\n",
        "\n",
        "        temp_file = tempfile.NamedTemporaryFile(delete=False)\n",
        "        self.temp_file_name = f\"{temp_file.name}.pdf\"\n",
        "        temp_file.close()\n",
        "    \n",
        "\n",
        "    @lru_cache(maxsize=256)\n",
        "    def get_text_as_list(self, text):\n",
        "        text = [s.strip() for s in text.split('\\n')]\n",
        "        text = [s for s in text if len(s) > 0]\n",
        "        names = list()\n",
        "        gender = list()\n",
        "        other = list()\n",
        "        return text\n",
        "\n",
        "    def download(self)->None:\n",
        "        \"\"\"Download the PDF file for this object\n",
        "\n",
        "        Returns:\n",
        "        None\n",
        "        \"\"\"\n",
        "        wget.download(self.pdf_url, self.temp_file_name)\n",
        "        if not os.path.isfile(self.temp_file_name) or \\\n",
        "            0 == os.stat(self.temp_file_name).st_size:\n",
        "            raise Exception(\"Failed to download file\")\n",
        "\n",
        "    def parse_first_page(self)->None:\n",
        "        \"\"\"\n",
        "        First page contains a lot of details, parse them\n",
        "        to fill the details of the geolocation of electoral roll\n",
        "        \"\"\"\n",
        "        re_town_village = re.compile(\".*town.*village\\s*[=:]\\s*(.*)\", \\\n",
        "                                    re.IGNORECASE)\n",
        "        re_post_office = re.compile(\".*Post.*Office\\s*[=:]\\s*(.*)\", \\\n",
        "                                    re.IGNORECASE)\n",
        "        re_pin_code = re.compile(\".*pin.*code.*\\s*([0-9]{6})\\s*\",\n",
        "                                    re.IGNORECASE)\n",
        "        re_block = re.compile(\".*block\\s[=:]\\s*(.*)\", re.IGNORECASE)\n",
        "        re_district = re.compile(\".*district\\s:\\s*(.*)\", re.IGNORECASE)\n",
        "        re_police_st = re.compile(\".*police.*station\\s*[=:]\\s*(.*)\",\\\n",
        "                                    re.IGNORECASE)\n",
        "        text = self.get_text_as_list(self.pages_text[0])\n",
        "        for s in text:\n",
        "            m = re_town_village.match(s)\n",
        "            if m:\n",
        "                self.town = m.group(1).strip()\n",
        "                continue\n",
        "            m = re_post_office.match(s)\n",
        "            if m:\n",
        "                self.post_office = m.group(1).strip()\n",
        "                continue\n",
        "            m = re_pin_code.match(s)\n",
        "            if m:\n",
        "                self.pin_code = m.group(1).strip()\n",
        "                continue\n",
        "            m = re_block.match(s)\n",
        "            if m:\n",
        "                self.block = m.group(1).strip()\n",
        "                continue\n",
        "            m = re_district.match(s)\n",
        "            if m:\n",
        "                self.district = m.group(1).strip()\n",
        "                continue\n",
        "            m = re_police_st.match(s)\n",
        "            if m:\n",
        "                self.police_station = m.group(1).strip()\n",
        "                continue\n",
        "        #print(f\"{self.town}, {self.post_office}, {self.block}, {self.police_station}, {self.district}, {self.pin_code}\")\n",
        "    \n",
        "    def convert_to_text(self, i:int)->None:\n",
        "        \"\"\"\n",
        "        Convert an image to text using pytesseract.\n",
        "        Pages from the PDF have already been converted to images\n",
        "        and stored in a dictionary indexed by page number\n",
        "        \"\"\"\n",
        "        s = pytesseract.image_to_string(self.pages[i])\n",
        "        s = s.replace(\"Age:\", \"\\r\\nAge:\")\n",
        "        s = s.replace(\"Photo is\", \"\\r\\nPhoto is\")\n",
        "        #s = s.replace(\"|\" , \"\\r\\n\")\n",
        "        #s = s.replace(\"[\", \"\\r\\n\")\n",
        "        #s = s.replace(\"]\", \"\\r\\n\")\n",
        "        return s\n",
        "\n",
        "    def get_other_name(self, s:str)->list:\n",
        "        \"\"\"\n",
        "        There can be several names in a single line as follows:\n",
        "        Fathers's Name: LAMJINGKMEN KHONGBUH Fathers' Name = LEM! CHALLAM Father's Name = PRECIOUSLY RYNGKHLEM\n",
        "        These need to be split and returned as a list\n",
        "        \"\"\"\n",
        "        matches = self.re_other_name.findall(s)\n",
        "        for a, b in matches:\n",
        "            s = s.replace(a, \"|\")\n",
        "        names = [x.strip() for x in s.split(\"|\")]\n",
        "        names = [x for x in names if len(x) > 0]\n",
        "        return names\n",
        "    \n",
        "    def get_name(self, s:str)->list:\n",
        "        \"\"\"\n",
        "        Do the same things for namess other's names\n",
        "        \"\"\"\n",
        "        matches = self.re_name.findall(s)\n",
        "        for a in matches:\n",
        "            s = s.replace(a, \"|\")\n",
        "        names = [x.strip() for x in s.split(\"|\")]\n",
        "        names = [x for x in names if len(x) > 0]\n",
        "        return names\n",
        "\n",
        "    def get_house_num(self, s:str)->list:\n",
        "        \"\"\"\n",
        "        Do the same thing for house number\n",
        "        \"\"\"\n",
        "        matches = self.re_house_num.findall(s)\n",
        "        for a in matches:\n",
        "            s = s.replace(a, \"|\")\n",
        "        names = [x.strip() for x in s.split(\"|\")]\n",
        "        names = [x for x in names if len(x) > 0]\n",
        "        return names\n",
        "\n",
        "    def get_age_gender(self, s:str)->tuple:\n",
        "        \"\"\"\n",
        "        Do the same thing for age and gender.\n",
        "        Age and gender appear in the same line.\n",
        "\n",
        "        This funciton matches lines that contain both age and gender\n",
        "        \n",
        "        There may be cases where lines contain only\n",
        "        age or only gender\n",
        "\n",
        "        Those are handled by get_age_only, and get_gender_only\n",
        "        \"\"\"\n",
        "        matches = self.re_age_gender.findall(s)\n",
        "        ages = list()\n",
        "        genders = list()\n",
        "        for _, age, gender in matches:\n",
        "            ages.append(age)\n",
        "            genders.append(gender)\n",
        "        return ages, genders\n",
        "\n",
        "    def get_age_only(self, s:str)->list:\n",
        "        \"\"\"\n",
        "        Do the same for age. Match lines that contain only age but not gender\n",
        "        \"\"\"\n",
        "        matches = self.re_age.findall(s)\n",
        "        ages = list()\n",
        "        assert(False)\n",
        "        return []\n",
        "\n",
        "    def get_temp_file_name(self)->str:\n",
        "        temp_file = tempfile.NamedTemporaryFile()\n",
        "        temp_file_name = f\"{temp_file.name}.json\"\n",
        "        temp_file.close()\n",
        "        return temp_file_name\n",
        "\n",
        "\n",
        "    def parse_roll_page(self, pagenum:int)->dict:\n",
        "        page_other_names = []\n",
        "        page_names = []\n",
        "        page_house_numbers = []\n",
        "        page_genders = []\n",
        "        page_ages = []\n",
        "\n",
        "        if not pagenum in self.pages_text:\n",
        "            raise Exception(\"page not found\")\n",
        "        text = self.get_text_as_list(self.pages_text[pagenum])\n",
        "        for s in text:\n",
        "            # Must match other name first, becuase\n",
        "            # the elif condition will also match\n",
        "            # and we should avoid that\n",
        "            if self.re_other_name_for_match.match(s):\n",
        "                page_other_names += self.get_other_name(s)\n",
        "            elif self.re_name.match(s):\n",
        "                page_names += self.get_name(s)\n",
        "            elif self.re_house_num_for_match.match(s):\n",
        "                page_house_numbers += self.get_house_num(s)\n",
        "            elif self.re_age_gender_for_match.match(s):\n",
        "                ages, genders = self.get_age_gender(s)\n",
        "                page_ages += ages\n",
        "                page_genders += genders\n",
        "            elif self.re_age_for_match.match(s):\n",
        "                page_ages += self.get_age_only()\n",
        "            else:\n",
        "                # print(f\"DIDN not match: |{s}|\")\n",
        "                pass\n",
        "\n",
        "\n",
        "        # Ensure that we have the same number of rows in each column\n",
        "        check_array = [len(page_other_names), len(page_names)]\n",
        "        check_array += [len(page_house_numbers), len(page_genders)]\n",
        "        check_array += [len(page_ages)]\n",
        "        # print(check_array)\n",
        "        for i in range(len(check_array) - 1):\n",
        "            x = check_array[i]\n",
        "            for y in check_array[i:]:\n",
        "                assert(min(x, 30) == min(y, 30))\n",
        "\n",
        "        ret_array = []\n",
        "        for name, o_name, housenum, gender, age in \\\n",
        "            zip(\\\n",
        "                page_names,\\\n",
        "                page_other_names,\\\n",
        "                page_house_numbers,\\\n",
        "                page_genders,\\\n",
        "                page_ages):\n",
        "            val = { \\\n",
        "                \"name\": name,\\\n",
        "                \"other_name\": o_name,\\\n",
        "                \"house_num\": housenum,\\\n",
        "                \"gender\": gender,\\\n",
        "                \"age\": age,\\\n",
        "                \"town\": self.town,\\\n",
        "                \"block\": self.block,\\\n",
        "                \"post_office\": self.post_office,\\\n",
        "                \"police_station\": self.police_station,\\\n",
        "                \"pin_code\": self.pin_code, \\\n",
        "            }\n",
        "            ret_array.append(val)\n",
        "\n",
        "        return ret_array\n",
        "            \n",
        "        \n",
        "\n",
        "    def process(self)->pd.DataFrame:\n",
        "        if not os.path.isfile(self.temp_file_name) or \\\n",
        "            0 == os.stat(self.temp_file_name).st_size:\n",
        "            raise Exception(\"Failed to download file\")\n",
        "        self.pages = pdf2image.convert_from_path(self.temp_file_name)\n",
        "        #self.pages = self.pages[:10] + [self.pages[-1]]\n",
        "        print(\"Converting pages to text...\")\n",
        "        self.pages_text = \\\n",
        "            {i: self.convert_to_text(i) for i in \\\n",
        "                tqdm.tqdm(range(len(self.pages)))}\n",
        "        self.parse_first_page()\n",
        "        print(f\"Parsing {len(self.pages)} pages\")\n",
        "\n",
        "        for i in tqdm.tqdm(range(3, len(self.pages) - 1)):\n",
        "            #print(f\"Parsing page: {i}\")\n",
        "            try:\n",
        "                self.voters += self.parse_roll_page(i)\n",
        "            except Exception as e:\n",
        "                print()\n",
        "                print(f\"Error in processing page: {i + 1}\")\n",
        "                print(f\"of {self.pdf_url}\")\n",
        "                print(f\"Skipped the page, please verify manually\")\n",
        "                self.errors += f\"Error in processing url: {self.url}\"\n",
        "                self.errors += f\"of {self.pdf_url}. \"\n",
        "                self.errors += f\"Skipped the page, please verify manually.\\n\"\n",
        "\n",
        "        temp_filename = self.get_temp_file_name() \n",
        "        with open(temp_filename, \"w\") as f:\n",
        "            json.dump(self.voters, f)\n",
        "        df = pd.read_json(temp_filename, orient=\"records\")\n",
        "        self.processed_df = df\n",
        "        return df\n",
        "        \n",
        "    def save(self)->None:\n",
        "        if self.savedir and \"\" != self.savedir and self.processed_df:\n",
        "            save_filename = f\"/content/gdrive/{self.savedir}/{self.save_filename}\"\n",
        "            save_filename_err = f\"{save_filename}.err\"\n",
        "            try:\n",
        "                if not os.path.isdir(self.savedir):\n",
        "                    os.makedirs(\\\n",
        "                                f\"/content/gdrive/{self.savedir}\",\\\n",
        "                                exist_ok=True)\n",
        "                if self.errors != \"\":\n",
        "                    with open(save_filename_err, w) as ferr:\n",
        "                        ferr.write(self.errors)\n",
        "                self.processed_df.to_csv(save_filename)\n",
        "            except Exception as e:\n",
        "                print(\"Failed to save the state\")\n",
        "                print(e)\n",
        "                \n",
        "\n",
        "    def __del__(self):\n",
        "        if os.path.exists(self.temp_file_name):\n",
        "            os.unlink(self.temp_file_name)\n"
      ],
      "metadata": {
        "id": "REL4OKurSkC9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add the links to the PDFs here:\n",
        "\n",
        "ONLINE_PDF_FILES_LIST = [\n",
        "    \"http://ceomeghalaya.nic.in/erolls/pdf/english/A001/A0010001.pdf\",\n",
        "    \"http://ceomeghalaya.nic.in/erolls/pdf/english/A001/A0010002.pdf\"\n",
        "]"
      ],
      "metadata": {
        "id": "0ux_Ro0tPBkC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Start here"
      ],
      "metadata": {
        "id": "_LlE-UIXcTOb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount(\"/content/gdrive\")\n",
        "roll = Roll(url=\"http://ceomeghalaya.nic.in/erolls/pdf/english/A001/A0010001.pdf\", save_directory=\"0000__DELETEME____\")\n",
        "\n",
        "roll.download()\n",
        "\n",
        "df = roll.process()\n",
        "roll.save()\n",
        "\n",
        "df.describe().T"
      ],
      "metadata": {
        "id": "cWxCqKyNbQUD",
        "outputId": "373e74c6-1175-4c61-c137-b025c794d0ba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converting pages to text...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/39 [00:00<?, ?it/s]\u001b[A\n",
            "  3%|▎         | 1/39 [00:03<02:19,  3.67s/it]\u001b[A\n",
            "  5%|▌         | 2/39 [00:05<01:30,  2.44s/it]\u001b[A\n",
            "  8%|▊         | 3/39 [00:14<03:21,  5.60s/it]\u001b[A\n",
            " 10%|█         | 4/39 [00:23<04:06,  7.03s/it]\u001b[A\n",
            " 13%|█▎        | 5/39 [00:33<04:36,  8.15s/it]\u001b[A\n",
            " 15%|█▌        | 6/39 [00:43<04:39,  8.46s/it]\u001b[A\n",
            " 18%|█▊        | 7/39 [00:52<04:37,  8.67s/it]\u001b[A\n",
            " 21%|██        | 8/39 [01:02<04:41,  9.07s/it]\u001b[A\n",
            " 23%|██▎       | 9/39 [01:11<04:36,  9.23s/it]\u001b[A\n",
            " 26%|██▌       | 10/39 [01:21<04:29,  9.30s/it]\u001b[A\n",
            " 28%|██▊       | 11/39 [01:30<04:23,  9.41s/it]\u001b[A\n",
            " 31%|███       | 12/39 [01:40<04:15,  9.45s/it]\u001b[A\n",
            " 33%|███▎      | 13/39 [01:49<04:06,  9.49s/it]\u001b[A\n",
            " 36%|███▌      | 14/39 [01:59<03:57,  9.50s/it]\u001b[A\n",
            " 38%|███▊      | 15/39 [02:09<03:49,  9.55s/it]\u001b[A\n",
            " 41%|████      | 16/39 [02:18<03:39,  9.56s/it]\u001b[A\n",
            " 44%|████▎     | 17/39 [02:28<03:30,  9.59s/it]\u001b[A\n",
            " 46%|████▌     | 18/39 [02:37<03:16,  9.34s/it]\u001b[A\n",
            " 49%|████▊     | 19/39 [02:46<03:07,  9.37s/it]\u001b[A\n",
            " 51%|█████▏    | 20/39 [02:55<02:56,  9.31s/it]\u001b[A\n",
            " 54%|█████▍    | 21/39 [03:05<02:50,  9.47s/it]\u001b[A\n",
            " 56%|█████▋    | 22/39 [03:16<02:48,  9.88s/it]\u001b[A\n",
            " 59%|█████▉    | 23/39 [03:26<02:38,  9.92s/it]\u001b[A\n",
            " 62%|██████▏   | 24/39 [03:35<02:25,  9.72s/it]\u001b[A\n",
            " 64%|██████▍   | 25/39 [03:45<02:14,  9.64s/it]\u001b[A\n",
            " 67%|██████▋   | 26/39 [03:55<02:07,  9.81s/it]\u001b[A\n",
            " 69%|██████▉   | 27/39 [04:05<02:00, 10.01s/it]\u001b[A\n",
            " 72%|███████▏  | 28/39 [04:15<01:49,  9.96s/it]\u001b[A\n",
            " 74%|███████▍  | 29/39 [04:26<01:43, 10.37s/it]\u001b[A\n",
            " 77%|███████▋  | 30/39 [04:34<01:26,  9.66s/it]\u001b[A\n",
            " 79%|███████▉  | 31/39 [04:46<01:21, 10.23s/it]\u001b[A\n",
            " 82%|████████▏ | 32/39 [04:56<01:10, 10.03s/it]\u001b[A\n",
            " 85%|████████▍ | 33/39 [05:05<00:59,  9.87s/it]\u001b[A\n",
            " 87%|████████▋ | 34/39 [05:07<00:37,  7.43s/it]\u001b[A\n",
            " 90%|████████▉ | 35/39 [05:17<00:32,  8.22s/it]\u001b[A\n",
            " 92%|█████████▏| 36/39 [05:28<00:27,  9.16s/it]\u001b[A\n",
            " 95%|█████████▍| 37/39 [05:33<00:15,  7.97s/it]\u001b[A\n",
            " 97%|█████████▋| 38/39 [05:40<00:07,  7.56s/it]\u001b[A\n",
            "100%|██████████| 39/39 [05:43<00:00,  8.81s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parsing 39 pages\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "100%|██████████| 35/35 [00:00<00:00, 1401.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Error in processing page: 13\n",
            "of http://ceomeghalaya.nic.in/erolls/pdf/english/A001/A0010001.pdf\n",
            "Skipped the page, please verify manually\n",
            "\n",
            "Error in processing page: 25\n",
            "of http://ceomeghalaya.nic.in/erolls/pdf/english/A001/A0010001.pdf\n",
            "Skipped the page, please verify manually\n",
            "\n",
            "Error in processing page: 26\n",
            "of http://ceomeghalaya.nic.in/erolls/pdf/english/A001/A0010001.pdf\n",
            "Skipped the page, please verify manually\n",
            "\n",
            "Error in processing page: 29\n",
            "of http://ceomeghalaya.nic.in/erolls/pdf/english/A001/A0010001.pdf\n",
            "Skipped the page, please verify manually\n",
            "\n",
            "Error in processing page: 30\n",
            "of http://ceomeghalaya.nic.in/erolls/pdf/english/A001/A0010001.pdf\n",
            "Skipped the page, please verify manually\n",
            "\n",
            "Error in processing page: 37\n",
            "of http://ceomeghalaya.nic.in/erolls/pdf/english/A001/A0010001.pdf\n",
            "Skipped the page, please verify manually\n",
            "              age  pin_code\n",
            "count  826.000000     826.0\n",
            "mean    37.627119  793150.0\n",
            "std     13.734590       0.0\n",
            "min     18.000000  793150.0\n",
            "25%     27.000000  793150.0\n",
            "50%     35.000000  793150.0\n",
            "75%     46.000000  793150.0\n",
            "max     97.000000  793150.0\n",
            "                      name         other_name house_num  gender  age  \\\n",
            "0        MARBELIN NONGPLUH           H KSHIAR        14    MALE   29   \n",
            "1     IAISHAHSLEM NONGPLUH   BRAKESPEAR LALOO        15  FEMALE   22   \n",
            "2       MEKERLANG NONGPLUH           BENI WAR        15    MALE   50   \n",
            "3         ARMY ROY PASTIEH      BENIS LYNGDOH         9  FEMALE   49   \n",
            "4    EWANMIKADAHUN LYNGDOH      THRIN LYNGDOH         9  FEMALE   25   \n",
            "..                     ...                ...       ...     ...  ...   \n",
            "821        BANRIHUN SUTING  SIBERLIN KHONGJOH       120  FEMALE   23   \n",
            "822          MANSHWA PHAWA     BERONIKA PHAWA       182    MALE   18   \n",
            "823     KITBOKLANG CHALLAM         KLIK LAWAI       194    MALE   18   \n",
            "824        SHINING CHALLAM      EBIAN CHALLAM        91    MALE   18   \n",
            "825      KONPHAMMI LYNGDOH     BLANBOR TALANG        43  FEMALE   18   \n",
            "\n",
            "         town        block post_office police_station  pin_code  \n",
            "0    UMLADANG  THADLASKEIN       JOWAI          JOWAI    793150  \n",
            "1    UMLADANG  THADLASKEIN       JOWAI          JOWAI    793150  \n",
            "2    UMLADANG  THADLASKEIN       JOWAI          JOWAI    793150  \n",
            "3    UMLADANG  THADLASKEIN       JOWAI          JOWAI    793150  \n",
            "4    UMLADANG  THADLASKEIN       JOWAI          JOWAI    793150  \n",
            "..        ...          ...         ...            ...       ...  \n",
            "821  UMLADANG  THADLASKEIN       JOWAI          JOWAI    793150  \n",
            "822  UMLADANG  THADLASKEIN       JOWAI          JOWAI    793150  \n",
            "823  UMLADANG  THADLASKEIN       JOWAI          JOWAI    793150  \n",
            "824  UMLADANG  THADLASKEIN       JOWAI          JOWAI    793150  \n",
            "825  UMLADANG  THADLASKEIN       JOWAI          JOWAI    793150  \n",
            "\n",
            "[826 rows x 10 columns]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "PpPq0ueLIyJJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}